{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e7c1169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import nltk\n",
    "import utils\n",
    "import markov_chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bdfebf",
   "metadata": {},
   "source": [
    "# Language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9774bfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[\n",
    "    \"<s> I am Sam </s>\",\n",
    "    \"<s> Sam I am </s>\",\n",
    "    \"<s> I do not like green eggs and ham </s>\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6375aeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1grams: 100%|██████████| 3/3 [00:00<00:00, 20068.44it/s]\n",
      "bag of 1grams: 3it [00:00, 1660.67it/s]\n"
     ]
    }
   ],
   "source": [
    "bag_of_words = utils.bag_of_ngrams(corpus=corpus, n=1, tokenize_function=utils.split_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a229b379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>I</th>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <th>am</th>\n",
       "      <th>Sam</th>\n",
       "      <th>do</th>\n",
       "      <th>not</th>\n",
       "      <th>like</th>\n",
       "      <th>green</th>\n",
       "      <th>eggs</th>\n",
       "      <th>and</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   <s>    I  </s>   am  Sam   do  not  like  green  eggs  and  ham\n",
       "0  1.0  1.0   1.0  1.0  1.0  0.0  0.0   0.0    0.0   0.0  0.0  0.0\n",
       "1  1.0  1.0   1.0  1.0  1.0  0.0  0.0   0.0    0.0   0.0  0.0  0.0\n",
       "2  1.0  1.0   1.0  0.0  0.0  1.0  1.0   1.0    1.0   1.0  1.0  1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f535ecae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2grams: 100%|██████████| 3/3 [00:00<00:00, 17898.88it/s]\n",
      "bag of 2grams: 3it [00:00, 1308.00it/s]\n"
     ]
    }
   ],
   "source": [
    "bigram = utils.bag_of_ngrams(corpus=corpus, n=2, tokenize_function=utils.split_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3058f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;s&gt; I</th>\n",
       "      <th>I am</th>\n",
       "      <th>am Sam</th>\n",
       "      <th>Sam &lt;/s&gt;</th>\n",
       "      <th>&lt;s&gt; Sam</th>\n",
       "      <th>Sam I</th>\n",
       "      <th>am &lt;/s&gt;</th>\n",
       "      <th>I do</th>\n",
       "      <th>do not</th>\n",
       "      <th>not like</th>\n",
       "      <th>like green</th>\n",
       "      <th>green eggs</th>\n",
       "      <th>eggs and</th>\n",
       "      <th>and ham</th>\n",
       "      <th>ham &lt;/s&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   <s> I  I am  am Sam  Sam </s>  <s> Sam  Sam I  am </s>  I do  do not  \\\n",
       "0    1.0   1.0     1.0       1.0      0.0    0.0      0.0   0.0     0.0   \n",
       "1    0.0   1.0     0.0       0.0      1.0    1.0      1.0   0.0     0.0   \n",
       "2    1.0   0.0     0.0       0.0      0.0    0.0      0.0   1.0     1.0   \n",
       "\n",
       "   not like  like green  green eggs  eggs and  and ham  ham </s>  \n",
       "0       0.0         0.0         0.0       0.0      0.0       0.0  \n",
       "1       0.0         0.0         0.0       0.0      0.0       0.0  \n",
       "2       1.0         1.0         1.0       1.0      1.0       1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19423d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams_compute_pw1_knowing_w2(w2, w1, bag_of_words, bigram):\n",
    "    p = bigram[f\"{w1} {w2}\"].sum() / bag_of_words[w1].sum()\n",
    "    print(f\"p({w2}|{w1})={p:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcd4e8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(I|<s>)=0.6667\n",
      "p(</s>|Sam)=0.5000\n",
      "p(eggs|green)=1.0000\n",
      "p(Sam|am)=0.5000\n",
      "p(am|I)=0.6667\n",
      "p(do|I)=0.3333\n"
     ]
    }
   ],
   "source": [
    "ngrams_compute_pw1_knowing_w2(w2=\"I\", w1=\"<s>\", bigram=bigram, bag_of_words=bag_of_words)\n",
    "ngrams_compute_pw1_knowing_w2(w2=\"</s>\", w1=\"Sam\", bigram=bigram, bag_of_words=bag_of_words)\n",
    "ngrams_compute_pw1_knowing_w2(w2=\"eggs\", w1=\"green\", bigram=bigram, bag_of_words=bag_of_words)\n",
    "ngrams_compute_pw1_knowing_w2(w2=\"Sam\", w1=\"am\", bigram=bigram, bag_of_words=bag_of_words)\n",
    "ngrams_compute_pw1_knowing_w2(w2=\"am\", w1=\"I\", bigram=bigram, bag_of_words=bag_of_words)\n",
    "ngrams_compute_pw1_knowing_w2(w2=\"do\", w1=\"I\", bigram=bigram, bag_of_words=bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c23e374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<s>', 'I', 'am', 'Sam', '</s>'],\n",
       " ['<s>', 'Sam', 'I', 'am', '</s>'],\n",
       " ['<s>', 'I', 'do', 'not', 'like', 'green', 'eggs', 'and', 'ham', '</s>']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus, words_freq = utils.split_tokenize(corpus=corpus)\n",
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feaedc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = list(words_freq.keys())\n",
    "markov_model = markov_chains.MarkovChains(states=states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a30d079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>',\n",
       " '<s>',\n",
       " 'I',\n",
       " 'Sam',\n",
       " 'am',\n",
       " 'and',\n",
       " 'do',\n",
       " 'eggs',\n",
       " 'green',\n",
       " 'ham',\n",
       " 'like',\n",
       " 'not']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markov_model.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75716388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08333334, 0.08333334, 0.08333334, 0.08333334, 0.08333334,\n",
       "        0.08333334, 0.08333334, 0.08333334, 0.08333334, 0.08333334,\n",
       "        0.08333334, 0.08333334],\n",
       "       [0.        , 0.        , 0.6666667 , 0.33333334, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.6666667 ,\n",
       "        0.        , 0.33333334, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.5       , 0.        , 0.5       , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.5       , 0.        , 0.        , 0.5       , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markov_model.fit(tokenized_corpus=tokenized_corpus)\n",
    "markov_model.transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e12fd64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999994, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markov_model.transition_matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fc9c8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most probabale next states:\n",
      "Current state: [</s>]  | next state: [</s>]  | with proba: p(</s>|</s>)=0.0833\n",
      "Current state: [<s>]   | next state: [I]     | with proba: p(<s>|I)=0.6667\n",
      "Current state: [I]     | next state: [am]    | with proba: p(I|am)=0.6667\n",
      "Current state: [Sam]   | next state: [</s>]  | with proba: p(Sam|</s>)=0.5000\n",
      "Current state: [am]    | next state: [</s>]  | with proba: p(am|</s>)=0.5000\n",
      "Current state: [and]   | next state: [ham]   | with proba: p(and|ham)=1.0000\n",
      "Current state: [do]    | next state: [not]   | with proba: p(do|not)=1.0000\n",
      "Current state: [eggs]  | next state: [and]   | with proba: p(eggs|and)=1.0000\n",
      "Current state: [green] | next state: [eggs]  | with proba: p(green|eggs)=1.0000\n",
      "Current state: [ham]   | next state: [</s>]  | with proba: p(ham|</s>)=1.0000\n",
      "Current state: [like]  | next state: [green] | with proba: p(like|green)=1.0000\n",
      "Current state: [not]   | next state: [like]  | with proba: p(not|like)=1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"Most probabale next states:\")\n",
    "for current_state in markov_model.states:\n",
    "    next_state, probas = markov_model.predict_next_state(current_state=current_state)\n",
    "    print(f\"Current state: [{current_state}]\".ljust(23)\n",
    "        + f\"| next state: [{next_state}]\".ljust(22)\n",
    "        + f\"| with proba: p({current_state}|{next_state})={probas.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fd9a423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate sequences:\n",
      "Seq1: <s> I am </s> </s> </s> </s> </s> </s> </s>\n",
      "Seq2: <s> I am </s> </s> </s> </s> </s> </s> </s>\n",
      "Seq3: I am </s> </s> </s> </s> </s> </s> </s> </s>\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate sequences:\")\n",
    "print(\"Seq1:\", \" \".join(markov_model.generate(start=None, length=10)))\n",
    "print(\"Seq2:\", \" \".join(markov_model.generate(start=\"<s>\", length=10)))\n",
    "print(\"Seq3:\", \" \".join(markov_model.generate(start=\"I\", length=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b665b51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation:\n",
      "machine translation : p(<s> I am)=0.4444 > p(<s> am I)=0.0000\n",
      "spell correction    : p(<s> I do not like)=0.2222 > p(<s> I do not lik)=0.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation:\")\n",
    "\n",
    "data = [\n",
    "    (\"machine translation\", \"<s> I am\", \"<s> am I\"),\n",
    "    (\"spell correction\", \"<s> I do not like\", \"<s> I do not lik\"),\n",
    "]\n",
    "\n",
    "for title, text1, text2 in data:\n",
    "    score1 = markov_model.score_sequence(sequence=text1.split())\n",
    "    score2 = markov_model.score_sequence(sequence=text2.split())\n",
    "    print(f\"{title.ljust(20)}: p({text1})={score1:.4f} > p({text2})={score2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f12df898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<s>', 'I', 'am', 'Sam', '</s>'],\n",
       " ['<s>', 'Sam', 'I', 'am', '</s>'],\n",
       " ['<s>', 'I', 'do', 'not', 'like', 'green', 'eggs', 'and', 'ham', '</s>']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5843f8fc",
   "metadata": {},
   "source": [
    "Using Wolof corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5add332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['french', 'wolof', 'sources'],\n",
       "    num_rows: 17777\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = load_dataset(\"galsenai/french-wolof-translation\")[\"train\"]\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b60a684a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bataaxal bii jëwriñu lu ajju ci mbiru bitim réew bu Ekuwatër moo ko wara wóoral, te dafa wara mengoo ak yenni càkuteef yi.\\n',\n",
       " '\"Amuñu woon benn jot ngir rawal sunu bopp.\\n',\n",
       " 'Ekost sa dëkk la te bëggna nu nga toog fi.\"\\n',\n",
       " 'Xibaari Jotna : Espaañ joxe na juróom-ñett-fukki milyaar ak ñeent ci xaalisu Seefa ngir dimbalee ko Senegaal.\\n',\n",
       " 'ñaata at nga am',\n",
       " 'Abu Usmaan Si, Mamadu Yoro Jàllo ak Usmaan Njaay ñoo faatu, ci doxu nemmeeku koom-koom gi bu Maki Sàll bi.\\n',\n",
       " 'Ni ñu ko tàmm a waxe fii : boo xamatul foo jëm, dellul fa nga jóge woon, baax na lool ñu dellu fa ñu jóge woon ngir bégal way-jëfandiku yi.\\n',\n",
       " 'Zambie réew la mu bokk ci ONU, Union Africaine, ak Southern African Development Community (SADC).',\n",
       " 'tooy',\n",
       " 'Ay teemeeri nit faatu ca donu bu Nias, ci tefesu Sumatra.\\n']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wolof_corpus = raw_data[\"wolof\"]\n",
    "wolof_corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9424569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_wolof_corpus, words_freq = utils.simple_tokenize(corpus=wolof_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1f4ed18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bataaxal',\n",
       "  'bii',\n",
       "  'jëwriñu',\n",
       "  'lu',\n",
       "  'ajju',\n",
       "  'ci',\n",
       "  'mbiru',\n",
       "  'bitim',\n",
       "  'réew',\n",
       "  'bu',\n",
       "  'ekuwatër',\n",
       "  'moo',\n",
       "  'ko',\n",
       "  'wara',\n",
       "  'wóoral',\n",
       "  'te',\n",
       "  'dafa',\n",
       "  'wara',\n",
       "  'mengoo',\n",
       "  'ak',\n",
       "  'yenni',\n",
       "  'càkuteef',\n",
       "  'yi'],\n",
       " ['amuñu', 'woon', 'benn', 'jot', 'ngir', 'rawal', 'sunu', 'bopp'],\n",
       " ['ekost', 'sa', 'dëkk', 'la', 'te', 'bëggna', 'nu', 'nga', 'toog', 'fi'],\n",
       " ['xibaari',\n",
       "  'jotna',\n",
       "  'espaañ',\n",
       "  'joxe',\n",
       "  'na',\n",
       "  'juróom',\n",
       "  'ñett',\n",
       "  'fukki',\n",
       "  'milyaar',\n",
       "  'ak',\n",
       "  'ñeent',\n",
       "  'ci',\n",
       "  'xaalisu',\n",
       "  'seefa',\n",
       "  'ngir',\n",
       "  'dimbalee',\n",
       "  'ko',\n",
       "  'senegaal'],\n",
       " ['ñaata', 'at', 'nga', 'am'],\n",
       " ['abu',\n",
       "  'usmaan',\n",
       "  'si',\n",
       "  'mamadu',\n",
       "  'yoro',\n",
       "  'jàllo',\n",
       "  'ak',\n",
       "  'usmaan',\n",
       "  'njaay',\n",
       "  'ñoo',\n",
       "  'faatu',\n",
       "  'ci',\n",
       "  'doxu',\n",
       "  'nemmeeku',\n",
       "  'koom',\n",
       "  'koom',\n",
       "  'gi',\n",
       "  'bu',\n",
       "  'maki',\n",
       "  'sàll',\n",
       "  'bi'],\n",
       " ['ni',\n",
       "  'ñu',\n",
       "  'ko',\n",
       "  'tàmm',\n",
       "  'a',\n",
       "  'waxe',\n",
       "  'fii',\n",
       "  'boo',\n",
       "  'xamatul',\n",
       "  'foo',\n",
       "  'jëm',\n",
       "  'dellul',\n",
       "  'fa',\n",
       "  'nga',\n",
       "  'jóge',\n",
       "  'woon',\n",
       "  'baax',\n",
       "  'na',\n",
       "  'lool',\n",
       "  'ñu',\n",
       "  'dellu',\n",
       "  'fa',\n",
       "  'ñu',\n",
       "  'jóge',\n",
       "  'woon',\n",
       "  'ngir',\n",
       "  'bégal',\n",
       "  'way',\n",
       "  'jëfandiku',\n",
       "  'yi'],\n",
       " ['zambie',\n",
       "  'réew',\n",
       "  'la',\n",
       "  'mu',\n",
       "  'bokk',\n",
       "  'ci',\n",
       "  'onu',\n",
       "  'union',\n",
       "  'africaine',\n",
       "  'ak',\n",
       "  'southern',\n",
       "  'african',\n",
       "  'development',\n",
       "  'community',\n",
       "  'sadc'],\n",
       " ['tooy'],\n",
       " ['ay',\n",
       "  'teemeeri',\n",
       "  'nit',\n",
       "  'faatu',\n",
       "  'ca',\n",
       "  'donu',\n",
       "  'bu',\n",
       "  'nias',\n",
       "  'ci',\n",
       "  'tefesu',\n",
       "  'sumatra']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_wolof_corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38fda6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_model = markov_chains.MarkovChains(states=list(words_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11ae5526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25466,\n",
       " ['0', '00', '000', '0006779', '000ngir', '007', '01', '012914', '02', '0230'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(markov_model.states), markov_model.states[:10] # I need a better tokenization function; more to come"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09152a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tfidf: 2900it [00:06, 457.03it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tf_idf \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mtfidf(corpus\u001b[38;5;241m=\u001b[39mwolof_corpus)\n",
      "File \u001b[0;32m~/Desktop/machine-learning-grind/11-nlp/02-language-modeling/utils.py\u001b[0m, in \u001b[0;36mtfidf\u001b[0;34m(corpus, vocab_size, tokenize_function)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tf_idf = utils.tfidf(corpus=wolof_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f12a8d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indi nañu lépp lu ci war ci li weesu wuute ak sàrt bii teew te jóge ci Kilifay nguur gi wala yi yor wàllu galag, te ñu mën see téye yii nekk ca : bu limat 0006779/MEF/DGID/BLEC bu ñaar-fukki fan ci weeru ut 2004 ; xibaar yi, bataaxal yi ak tontu waa nguur gi te jóge ca kër jëwriñ ja yor wàllu koom ak koppaaral ak barab bu mag bay doxal mbirum galag ak këyit yi ci aju.\n",
      " Sont rapportées toutes dispositions réglementaires antérieures contraires à la présente loi émanant des autorités administratives ou fiscales, notamment celles contenues dans: la circulaire n° 0006779/MEF/DGID/BLEC du 20 août 2004; les circulaires, notes, lettres et réponses administratives émanant du Ministère de l’Economie et des finances et de la Direction générale des Impôts et des Domaines.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ex, l in zip(wolof_corpus, raw_data[\"french\"]) :\n",
    "    if \"0006779\" in ex.lower():\n",
    "        print(ex, l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
